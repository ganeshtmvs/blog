{
  
    
        "post0": {
            "title": "COVID-19 India Matplotlib Overview",
            "content": "India . Last update: 28th July, 2020 . Confirmed cases: . 1514800 (+49001) . Confirmed deaths: . 34121 (+770) . states Cases Deaths PCases PDeaths Cases (+) Deaths (+) Fatality Rate Maharashtra 391440 14164 383723 13882 7717 282 3.62 Tamil Nadu 227688 3659 220716 3571 6972 88 1.61 Delhi 132275 3881 131219 3853 1056 28 2.93 Andhra Pradesh 110297 1148 102349 1090 7948 58 1.04 Karnataka 107001 2064 101465 1962 5536 102 1.93 Uttar Pradesh 73951 1497 70493 1456 3458 41 2.02 West Bengal 62964 1449 60830 1411 2134 38 2.30 Gujarat 57982 2372 56874 2348 1108 24 4.09 Telangana 57142 480 55532 471 1610 9 0.84 Bihar 43591 269 41111 255 2480 14 0.62 Rajasthan 38636 644 37564 633 1072 11 1.67 Assam 34846 92 33475 90 1371 2 0.26 Haryana 32876 406 32127 397 749 9 1.23 Madhya Pradesh 29217 831 28589 821 628 10 2.84 Orissa 28107 189 26892 181 1215 8 0.67 Kerala 20895 68 19728 64 1167 4 0.33 Jammu and Kashmir 18879 333 18390 321 489 12 1.76 Punjab 14378 336 13769 318 609 18 2.34 Jharkhand 9563 94 8803 90 760 4 0.98 Goa 5287 36 5119 36 168 0 0.68 Tripura 4287 21 4066 17 221 4 0.49 Pondicherry 3013 47 2874 43 139 4 1.56 Himachal Pradesh 2330 13 2270 13 60 0 0.56 Manipur 2317 0 2286 0 31 0 0.00 Nagaland 1460 4 1385 5 75 0 0.27 Arunachal Pradesh 1330 3 1239 3 91 0 0.23 Chandigarh 934 14 910 14 24 0 1.50 Meghalaya 779 5 738 5 41 0 0.64 Sikkim 592 1 568 1 24 0 0.17 Mizoram 384 0 361 0 23 0 0.00 Andaman and Nicobar Islands 359 1 334 1 25 0 0.28 Daman and Diu 0 0 0 0 0 0 NaN Lakshadweep 0 0 0 0 0 0 NaN .",
            "url": "https://ganeshtmvs.github.io/blog/2021/07/17/2020-07-28-Covid-Dashboard.html",
            "relUrl": "/2021/07/17/2020-07-28-Covid-Dashboard.html",
            "date": " • Jul 17, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Distinguish Your Own Digits (DYOD)",
            "content": "A classifier that distinguishes between the number 3 and number 8. . %load_ext autoreload %autoreload 2 . %matplotlib inline import numpy as np import matplotlib.pyplot as plt import pandas as pd . From the command line run pip install mnist. This is a library that will help you bring down the mnist dataset. If you run this from a notebook, you need to put !pip install mnist in a cell by itself. . !pip install mnist . Requirement already satisfied: mnist in c: users lenovo anaconda3 lib site-packages (0.2.2) Requirement already satisfied: numpy in c: users lenovo anaconda3 lib site-packages (from mnist) (1.18.1) . Preparing the Data . import mnist . train_images = mnist.train_images() train_labels = mnist.train_labels() . train_images.shape, train_labels.shape . ((60000, 28, 28), (60000,)) . test_images = mnist.test_images() test_labels = mnist.test_labels() test_labels[0:2] . array([7, 2], dtype=uint8) . test_images.shape, test_labels.shape . ((10000, 28, 28), (10000,)) . image_index = 7776 # You may select anything up to 60,000 print(train_labels[image_index]) plt.imshow(train_images[image_index], cmap=&#39;Greys&#39;) #plt.imshow(test_images[image_index], cmap=&#39;Greys&#39;) . 2 . &lt;matplotlib.image.AxesImage at 0x13a295ac448&gt; . Filter data to get 3 and 8 out . train_filter = np.where((train_labels == 3 ) | (train_labels == 8)) test_filter = np.where((test_labels == 3) | (test_labels == 8)) X_train, y_train = train_images[train_filter], train_labels[train_filter] X_test, y_test = test_images[test_filter], test_labels[test_filter] . We normalize the pizel values in the 0 to 1 range . X_train = X_train/255. X_test = X_test/255. . And setup the labels as 1 (when the digit is 3) and 0 (when the digit is 8) . y_train = 1*(y_train==3) y_test = 1*(y_test==3) . X_train.shape, X_test.shape . ((11982, 28, 28), (1984, 28, 28)) . We reshape the data to flatten the image pixels into a set of features or co-variates: . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . X_train = X_train.reshape(X_train.shape[0], -1) X_test = X_test.reshape(X_test.shape[0], -1) X_train.shape, X_test.shape . ((11982, 784), (1984, 784)) . Importing appropriate functions from &#39;Kudzu_a&#39; . from kudzu_a.layer import Sigmoid from kudzu_a.layer import Relu from kudzu_a.layer import Affine, Sigmoid from kudzu_a.model import Model from kudzu_a.train import Learner from kudzu_a.optim import GD from kudzu_a.data import Data, Dataloader, Sampler from kudzu_a.callbacks import AccCallback from kudzu_a.callbacks import ClfCallback from kudzu_a.loss import MSE . #creating a Config class, to store important parameters. class Config: pass config = Config() config.lr = 0.001 config.num_epochs = 251 config.bs = 50 . #initialising variables data = Data(X_train, y_train.reshape(-1,1)) sampler = Sampler(data, config.bs, shuffle=True) dl = Dataloader(data, sampler) opt = GD(config.lr) loss = MSE() . training_xdata = X_train testing_xdata = X_test training_ydata = y_train.reshape(-1,1) testing_ydata = y_test.reshape(-1,1) . Training the model . # layers for the Neural Network layers = [Affine(&quot;first&quot;, 784, 100), Relu(&quot;first&quot;), Affine(&quot;second&quot;, 100, 100), Relu(&quot;second&quot;), Affine(&quot;third&quot;, 100, 2), Affine(&quot;final&quot;, 2, 1), Sigmoid(&quot;final&quot;)] model_nn = Model(layers) # layers for the Logistic Regression layers_lr = [Affine(&quot;logits&quot;, 784, 1), Sigmoid(&quot;sigmoid&quot;)] model_lr = Model(layers_lr) . learner_nn = Learner(loss, model_nn, opt, config.num_epochs) acc_nn = ClfCallback(learner_nn, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_nn.set_callbacks([acc_nn]) learner_nn.train_loop(dl) . Epoch 0, Loss 0.2551 Training Accuracy: 0.5253, Testing Accuracy: 0.5091 Epoch 10, Loss 0.1404 Training Accuracy: 0.8927, Testing Accuracy: 0.8876 Epoch 20, Loss 0.0713 Training Accuracy: 0.9316, Testing Accuracy: 0.9395 Epoch 30, Loss 0.0503 Training Accuracy: 0.9478, Testing Accuracy: 0.9577 Epoch 40, Loss 0.0413 Training Accuracy: 0.9555, Testing Accuracy: 0.9627 Epoch 50, Loss 0.0365 Training Accuracy: 0.9590, Testing Accuracy: 0.9662 Epoch 60, Loss 0.0333 Training Accuracy: 0.9614, Testing Accuracy: 0.9677 Epoch 70, Loss 0.0311 Training Accuracy: 0.9638, Testing Accuracy: 0.9677 Epoch 80, Loss 0.0293 Training Accuracy: 0.9654, Testing Accuracy: 0.9682 Epoch 90, Loss 0.0279 Training Accuracy: 0.9677, Testing Accuracy: 0.9682 Epoch 100, Loss 0.0267 Training Accuracy: 0.9690, Testing Accuracy: 0.9693 Epoch 110, Loss 0.0256 Training Accuracy: 0.9700, Testing Accuracy: 0.9698 Epoch 120, Loss 0.0247 Training Accuracy: 0.9707, Testing Accuracy: 0.9698 Epoch 130, Loss 0.0239 Training Accuracy: 0.9714, Testing Accuracy: 0.9698 Epoch 140, Loss 0.0232 Training Accuracy: 0.9731, Testing Accuracy: 0.9703 Epoch 150, Loss 0.0225 Training Accuracy: 0.9740, Testing Accuracy: 0.9713 Epoch 160, Loss 0.0219 Training Accuracy: 0.9750, Testing Accuracy: 0.9718 Epoch 170, Loss 0.0214 Training Accuracy: 0.9755, Testing Accuracy: 0.9718 Epoch 180, Loss 0.0209 Training Accuracy: 0.9760, Testing Accuracy: 0.9728 Epoch 190, Loss 0.0204 Training Accuracy: 0.9767, Testing Accuracy: 0.9733 Epoch 200, Loss 0.0199 Training Accuracy: 0.9773, Testing Accuracy: 0.9738 Epoch 210, Loss 0.0195 Training Accuracy: 0.9777, Testing Accuracy: 0.9743 Epoch 220, Loss 0.019 Training Accuracy: 0.9785, Testing Accuracy: 0.9743 Epoch 230, Loss 0.0186 Training Accuracy: 0.9796, Testing Accuracy: 0.9743 Epoch 240, Loss 0.0183 Training Accuracy: 0.9796, Testing Accuracy: 0.9743 Epoch 250, Loss 0.0179 Training Accuracy: 0.9801, Testing Accuracy: 0.9748 . 0.01934826534316111 . learner_lr = Learner(loss, model_lr, opt, config.num_epochs) acc_lr = ClfCallback(learner_lr, config.bs, training_xdata , testing_xdata, training_ydata, testing_ydata) learner_lr.set_callbacks([acc_lr]) learner_lr.train_loop(dl) . Epoch 0, Loss 0.2632 Training Accuracy: 0.5903, Testing Accuracy: 0.6048 Epoch 10, Loss 0.1092 Training Accuracy: 0.8940, Testing Accuracy: 0.9073 Epoch 20, Loss 0.0832 Training Accuracy: 0.9190, Testing Accuracy: 0.9330 Epoch 30, Loss 0.0712 Training Accuracy: 0.9305, Testing Accuracy: 0.9420 Epoch 40, Loss 0.064 Training Accuracy: 0.9370, Testing Accuracy: 0.9466 Epoch 50, Loss 0.0591 Training Accuracy: 0.9411, Testing Accuracy: 0.9526 Epoch 60, Loss 0.0555 Training Accuracy: 0.9443, Testing Accuracy: 0.9567 Epoch 70, Loss 0.0527 Training Accuracy: 0.9464, Testing Accuracy: 0.9567 Epoch 80, Loss 0.0505 Training Accuracy: 0.9493, Testing Accuracy: 0.9577 Epoch 90, Loss 0.0487 Training Accuracy: 0.9506, Testing Accuracy: 0.9577 Epoch 100, Loss 0.0472 Training Accuracy: 0.9520, Testing Accuracy: 0.9602 Epoch 110, Loss 0.0458 Training Accuracy: 0.9525, Testing Accuracy: 0.9627 Epoch 120, Loss 0.0447 Training Accuracy: 0.9537, Testing Accuracy: 0.9622 Epoch 130, Loss 0.0437 Training Accuracy: 0.9542, Testing Accuracy: 0.9627 Epoch 140, Loss 0.0428 Training Accuracy: 0.9552, Testing Accuracy: 0.9627 Epoch 150, Loss 0.042 Training Accuracy: 0.9558, Testing Accuracy: 0.9637 Epoch 160, Loss 0.0413 Training Accuracy: 0.9564, Testing Accuracy: 0.9647 Epoch 170, Loss 0.0407 Training Accuracy: 0.9571, Testing Accuracy: 0.9652 Epoch 180, Loss 0.0401 Training Accuracy: 0.9583, Testing Accuracy: 0.9652 Epoch 190, Loss 0.0395 Training Accuracy: 0.9587, Testing Accuracy: 0.9662 Epoch 200, Loss 0.039 Training Accuracy: 0.9590, Testing Accuracy: 0.9667 Epoch 210, Loss 0.0386 Training Accuracy: 0.9596, Testing Accuracy: 0.9667 Epoch 220, Loss 0.0381 Training Accuracy: 0.9601, Testing Accuracy: 0.9667 Epoch 230, Loss 0.0377 Training Accuracy: 0.9604, Testing Accuracy: 0.9672 Epoch 240, Loss 0.0373 Training Accuracy: 0.9604, Testing Accuracy: 0.9677 Epoch 250, Loss 0.037 Training Accuracy: 0.9605, Testing Accuracy: 0.9677 . 0.04265239562277071 . plt.figure(figsize=(15,10)) # Neural Network plots plt.plot(acc_nn.accuracies, &#39;r-&#39;, label = &quot;Training Accuracies - NN&quot;) plt.plot(acc_nn.test_accuracies, &#39;g-&#39;, label = &quot;Testing Accuracies - NN&quot;) # Logistic Regression plots plt.plot(acc_lr.accuracies, &#39;k-&#39;, label = &quot;Training Accuracies - LR&quot;) plt.plot(acc_lr.test_accuracies, &#39;b-&#39;, label = &quot;Testing Accuracies - LR&quot;) plt.ylim(0.8, 1) plt.legend() . &lt;matplotlib.legend.Legend at 0x13a71cc2dc8&gt; . Plotting the outputs of this layer of the NN. . model_new = Model(layers[:-2]) plot_testing = model_new(testing_xdata) . Plotting the scatter plot of points and color coding by class . plt.figure(figsize=(8,7)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()); plt.title(&#39;Outputs&#39;) . Text(0.5, 1.0, &#39;Outputs&#39;) . Probability contours . model_prob = Model(layers[-2:]) # Adjust the x and y ranges according to the above generated plot. x_range = np.linspace(-4, 1, 100) y_range = np.linspace(-6, 6, 100) x_grid, y_grid = np.meshgrid(x_range, y_range) # x_grid and y_grig are of size 100 X 100 # converting x_grid and y_grid to continuous arrays x_grid_flat = np.ravel(x_grid) y_grid_flat = np.ravel(y_grid) # The last layer of the current model takes two columns as input. Hence transpose of np.vstack() is required. X = np.vstack((x_grid_flat, y_grid_flat)).T # x_grid and y_grid are of size 100 x 100 probability_contour = model_prob(X).reshape(100,100) . plt.figure(figsize=(10,9)) plt.scatter(plot_testing[:,0], plot_testing[:,1], alpha = 0.1, c = y_test.ravel()) contours = plt.contour(x_grid,y_grid,probability_contour) plt.title(&#39;Probability Contours&#39;) plt.clabel(contours, inline = True ); .",
            "url": "https://ganeshtmvs.github.io/blog/2020/08/12/project-univ.ai.html",
            "relUrl": "/2020/08/12/project-univ.ai.html",
            "date": " • Aug 12, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "Covid-19 Dashboard: Daily updates",
            "content": "This version of the dashboard updates itself everyday with the latest information. . India . Last update: 11-Aug-20 . Confirmed cases: . 2328313 (+61252) . Confirmed deaths: . 46199 (+835) . Last Updated: 11:26:55.111405 .",
            "url": "https://ganeshtmvs.github.io/blog/2020/08/11/Daily-Covid-Updates.html",
            "relUrl": "/2020/08/11/Daily-Covid-Updates.html",
            "date": " • Aug 11, 2020"
        }
        
    
  

  
  

  

  
  

  
  

  
  

  
  

  
  

  
      ,"page7": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ganeshtmvs.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}